In this chapter we present the comparison in performance between our results using the LLM in the way described in \autoref{chap:large-language-model}, and the simpler models described in \autoref{chap:other-models}.

For each dataset, we have experimented with a few different pairs (\verb|pred_len|, \verb|seq_step|), and chose the one, where the LLM performed best on the final epoch, i.e. had highest accuracy. Then, we've trained the other 4 simpler models with these parameters, to see how they compare.

In this chapter we present the results in the following way: for each dataset described in \autoref{chap:preliminary-definitions}, we have one row. The table presents accuracies each model achieves at predicting the price \verb|Prediction Timestep| time into the future. Next to the name of each dataset is a tuple of the form (\verb|pred_len|, \verb|seq_step|) with which parameters the models were trained.

For each dataset, the best accuracy score has been bolded.

\section{Results}

\begin{center}
	\begin{tabular}{|| c || c | c | c | c | c | c ||}
		\hline
		\multicolumn{7}{|c|}{Dataset model \emph{accuracy} results}                                                                                                                                          \\
		\hline
		Dataset name        & \vtop{\hbox{\strut Prediction}\hbox{\strut timestep}} & \vtop{\hbox{\strut Linear}\hbox{\strut Regression}} & MLP              & CNN              & ResNet  & LLM              \\ [0.5ex]
		\hline\hline
		AAPL (40, 1)        & 40 days                                               & 63.55\%                                             & \textbf{65.42}\% & 34.92\%          & 34.92\% & 60.12\%          \\
		\hline
		BTCUSD (5, 2)       & 10 hours                                              & 48.54\%                                             & 46.66\%          & 45.31\%          & 45.56\% & \textbf{50.54}\% \\
		\hline
		EURUSD (7,7)        & 49 hours                                              & 49.27\%                                             & 47.47\%          & 53.48\%          & 49.87\% & \textbf{55.46}\% \\
		\hline
		GBPCAD (10, 7)      & 70 hours                                              & 53.03\%                                             & 49.08\%          & \textbf{53.67}\% & 43.93\% & 51.45\%          \\
		\hline
		GBPTRY (5, 2)       & 10 hours                                              & 54.79\%                                             & \textbf{58.64}\% & 41.97\%          & 40.93\% & 54.65\%          \\
		\hline
		Electricity (6, 11) & 990 minutes                                           & 57.81\%                                             & 66.87\%          & 65.31\%          & 50.62\% & \textbf{68.78}\% \\
		\hline
		US500 (10, 1)       & 10 hours                                              & 42.54\%                                             & 44.00\%          & 43.49\%          & 41.12\% & \textbf{53.37}\% \\
		\hline

		\hline
	\end{tabular}
\end{center}


Overall, as can be seen from the above summary, the LLM performs quite well when compared to other models. It is not however consistently best. MLP and CNN models sometimes manage to achieve higher accuracy than LLM.

In AAPL dataset, the advantage is quite clearly in favour of MLP, where Linear Regression also does very well. The AAPL dataset is distinguished by its relatively small size and longer timestep, indicating that perhaps MLP and Linear Regression do better with such datasets.

In GBPCAD and GBPTRY datasets, the advantage of Linear Regression, MLP and CNN is less pronounced, though still noticable.

In other datasets our LLM construction takes the lead, with at least 2\% of an advantage over the second best model. This is most pronounced in the US500 dataset, where the accuracy of other models is below 45\%, whereas LLM achieves a score of over 53\%. As US500 is an aggregated index of US top 500 companies, this may mean, that LLM is better able to capture the more complex nature of such a dataset.
\\[100pt]
